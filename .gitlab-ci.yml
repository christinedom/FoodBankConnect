stages:
  - build
  - deploy         
  - backend_release 
  - backend_test    
  - selenium_tests

# ------------------------------------------------
# GLOBAL ENVIRONMENT VARIABLES
# ------------------------------------------------
variables:
  REQUIREMENTS_FILE: "backend/requirements.txt"
  PYTEST_WORKDIR: "backend"
  REPORT_DIR: "reports"
  PYTEST_JUNIT_XML: "$REPORT_DIR/pytest-report.xml"
  PYTEST_COVERAGE_XML: "$REPORT_DIR/coverage.xml"
  POSTMAN_COLLECTION: "tests/postman/collection.json"
  NEWMAN_JUNIT_XML: "$REPORT_DIR/newman-results.xml"

# ------------------------------------------------
# Frontend build and deploy remain the same
# ------------------------------------------------
build_react:
  stage: build
  image: node:20-bullseye
  script:
    - cd frontend
    - npm ci
    - CI=false npm run build
  artifacts:
    paths:
      - frontend/build
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: on_success
    - when: never

deploy_website:
  stage: deploy
  image:
    name: amazon/aws-cli
    entrypoint: [""]
  script:
    - aws s3 sync frontend/build/ s3://$S3_BUCKET --delete
    - aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_DIST_ID --paths "/*"
  dependencies:
    - build_react
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: on_success
    - when: never

# ------------------------------------------------
# Backend: Unit tests with pytest
# ------------------------------------------------
backend_unit_tests:
  stage: backend_test
  image: python:3.12-bullseye
  before_script:
    - python -V
    - pip install -r "$REQUIREMENTS_FILE"
    - pip install pytest pytest-cov
    - mkdir -p "$CI_PROJECT_DIR/$REPORT_DIR"
  script:
    - |
      if [ -n "$PYTEST_WORKDIR" ]; then cd "$PYTEST_WORKDIR"; fi
      pytest -q --maxfail=1 --disable-warnings         --cov=.         --cov-report=xml:"$CI_PROJECT_DIR/$PYTEST_COVERAGE_XML"         --junitxml "$CI_PROJECT_DIR/$PYTEST_JUNIT_XML"
  artifacts:
    when: always
    reports:
      junit: $PYTEST_JUNIT_XML
      coverage_report:
        coverage_format: cobertura
        path: $PYTEST_COVERAGE_XML
    paths:
      - $PYTEST_JUNIT_XML
      - $PYTEST_COVERAGE_XML
  rules:
    - when: on_success

# ------------------------------------------------
# Backend: API tests with Newman/Postman
# ------------------------------------------------
backend_api_tests:
  stage: backend_test
  image: node:20-bullseye
  before_script:
    - apt-get update && apt-get install -y curl python3 python3-pip
    - pip install -r "$REQUIREMENTS_FILE"
    - npm install -g newman
    - mkdir -p "$CI_PROJECT_DIR/$REPORT_DIR"
  script:
    - if [ -f main.py ]; then python3 main.py & echo $! > flask.pid; fi
    - for i in {1..60}; do curl -sf http://localhost:8080/health && break; sleep 1; done || true
    - newman run "$POSTMAN_COLLECTION"         --reporters cli,junit         --reporter-junit-export "$CI_PROJECT_DIR/$NEWMAN_JUNIT_XML" || NEWMAN_RC=$?
    - if [ -f flask.pid ]; then kill $(cat flask.pid) || true; fi
    - if [ ! -s "$CI_PROJECT_DIR/$NEWMAN_JUNIT_XML" ]; then echo "<testsuite></testsuite>" > "$CI_PROJECT_DIR/$NEWMAN_JUNIT_XML"; fi
    - exit ${NEWMAN_RC:-0}
  artifacts:
    when: always
    reports:
      junit: $NEWMAN_JUNIT_XML
    paths:
      - $NEWMAN_JUNIT_XML
  rules:
    - when: on_success
